{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# NYC Taxi DLT Pipeline with Autoloader\n",
        "\n",
        "This Delta Live Tables (DLT) pipeline implements true streaming using Databricks Autoloader:\n",
        "- **Landing Zone**: Autoloader reads from volume files for true streaming\n",
        "- **Bronze Layer**: Cleansed and validated taxi trip data\n",
        "- **Data Quality**: Monitoring and validation\n",
        "\n",
        "**Data Flow:**\n",
        "1. Data export job writes batches to `/Volumes/nyc_trips_dev/bronze/landing_zone_nyctrips`\n",
        "2. Autoloader detects new files and streams them\n",
        "3. DLT processes streaming data through bronze layer\n",
        "\n",
        "Pipeline defined in resources/ghithub_trends_digger.pipeline.yml\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import required libraries\n",
        "import dlt\n",
        "import sys\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import (\n",
        "    col, when, coalesce, current_timestamp, lit, \n",
        "    count, countDistinct, approx_count_distinct, avg, min, max, date_trunc,\n",
        "    expr, isnotnull\n",
        ")\n",
        "from pyspark.sql.types import TimestampType, DoubleType, IntegerType\n",
        "\n",
        "# Get Spark session (works in DLT environment)\n",
        "spark = SparkSession.getActiveSession()\n",
        "if spark is None:\n",
        "    spark = SparkSession.builder.getOrCreate()\n",
        "\n",
        "# Add src path for custom modules\n",
        "bundle_path = spark.conf.get(\"bundle.sourcePath\", \".\")\n",
        "if bundle_path:\n",
        "    sys.path.append(bundle_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# LANDING ZONE - Raw streaming data from volume files\n",
        "# =============================================================================\n",
        "\n",
        "@dlt.table(\n",
        "    name=\"taxi_raw_landing\",\n",
        "    comment=\"Raw NYC taxi data streaming from volume files using Autoloader\",\n",
        "    table_properties={\n",
        "        \"quality\": \"bronze\",\n",
        "        \"layer\": \"landing\" \n",
        "    }\n",
        ")\n",
        "def taxi_raw_landing():\n",
        "    \"\"\"\n",
        "    Stream raw taxi data from volume files using Databricks Autoloader.\n",
        "    \n",
        "    This table reads parquet files as they arrive in the landing zone volume,\n",
        "    providing true streaming ingestion without full table refreshes.\n",
        "    \"\"\"\n",
        "    return (\n",
        "        spark.readStream\n",
        "        .format(\"cloudFiles\")\n",
        "        .option(\"cloudFiles.format\", \"parquet\")\n",
        "        .option(\"cloudFiles.schemaLocation\", \"/Volumes/nyc_trips_dev/bronze/landing_zone/_schemas\")\n",
        "        .option(\"cloudFiles.includeExistingFiles\", \"true\")\n",
        "        .option(\"cloudFiles.maxFilesPerTrigger\", \"10\")  # Control batch size\n",
        "        .load(\"/Volumes/nyc_trips_dev/bronze/landing_zone\")\n",
        "        .withColumn(\"dlt_load_timestamp\", current_timestamp())\n",
        "        .withColumn(\"dlt_file_path\", col(\"_metadata.file_path\"))\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# BRONZE LAYER - Cleansed and validated streaming data\n",
        "# =============================================================================\n",
        "\n",
        "@dlt.table(\n",
        "    name=\"taxi_bronze\",\n",
        "    comment=\"Cleansed and validated NYC taxi trips with data quality checks\",\n",
        "    table_properties={\n",
        "        \"quality\": \"bronze\",\n",
        "        \"layer\": \"bronze\"\n",
        "    }\n",
        ")\n",
        "@dlt.expect_or_fail(\"valid_pickup_datetime\", \"tpep_pickup_datetime IS NOT NULL\")\n",
        "@dlt.expect_or_fail(\"valid_dropoff_datetime\", \"tpep_dropoff_datetime IS NOT NULL\") \n",
        "@dlt.expect_or_fail(\"valid_trip_distance\", \"trip_distance >= 0\")\n",
        "@dlt.expect_or_fail(\"valid_fare_amount\", \"fare_amount > 0\")\n",
        "@dlt.expect_or_drop(\"reasonable_fare\", \"fare_amount < 1000\")  # Drop extreme outliers\n",
        "@dlt.expect(\"valid_zip_codes\", \"pickup_zip > 0 AND dropoff_zip > 0\")\n",
        "def taxi_bronze():\n",
        "    \"\"\"\n",
        "    Bronze layer with data quality validations applied to streaming taxi data.\n",
        "    \n",
        "    Quality Rules:\n",
        "    - Fail pipeline if core datetime/amount fields are null/invalid\n",
        "    - Drop records with unreasonable fare amounts (>$1000)\n",
        "    - Warn on invalid zip codes but continue processing\n",
        "    \"\"\"\n",
        "    return (\n",
        "        dlt.read_stream(\"taxi_raw_landing\")\n",
        "        .select(\n",
        "            col(\"tpep_pickup_datetime\").cast(TimestampType()),\n",
        "            col(\"tpep_dropoff_datetime\").cast(TimestampType()),\n",
        "            col(\"trip_distance\").cast(DoubleType()),\n",
        "            col(\"fare_amount\").cast(DoubleType()),\n",
        "            col(\"pickup_zip\").cast(IntegerType()),\n",
        "            col(\"dropoff_zip\").cast(IntegerType()),\n",
        "            col(\"export_timestamp\"),\n",
        "            col(\"batch_id\"),\n",
        "            col(\"source_system\"),\n",
        "            col(\"export_hour\"),\n",
        "            col(\"dlt_load_timestamp\"),\n",
        "            col(\"dlt_file_path\")\n",
        "        )\n",
        "        .withColumn(\"trip_duration_minutes\", \n",
        "                   (col(\"tpep_dropoff_datetime\").cast(\"long\") - \n",
        "                    col(\"tpep_pickup_datetime\").cast(\"long\")) / 60)\n",
        "        .withColumn(\"is_valid_trip\", \n",
        "                   when((col(\"trip_duration_minutes\") > 0) & \n",
        "                        (col(\"trip_duration_minutes\") < 600), True).otherwise(False))  # 0-10 hours\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# SILVER LAYER - Business logic transformations\n",
        "# =============================================================================\n",
        "\n",
        "@dlt.table(\n",
        "    name=\"silver.taxi_silver_trips\", \n",
        "    comment=\"Enriched taxi trips with business logic and aggregations\",\n",
        "    table_properties={\n",
        "        \"quality\": \"silver\",\n",
        "        \"layer\": \"silver\"\n",
        "    }\n",
        ")\n",
        "def taxi_silver_trips():\n",
        "    \"\"\"\n",
        "    Silver layer with business transformations:\n",
        "    - Trip categorization (short/medium/long distance)\n",
        "    - Fare efficiency metrics\n",
        "    - Time-based enrichments\n",
        "    \"\"\"\n",
        "    return (\n",
        "        dlt.read_stream(\"taxi_bronze\")\n",
        "        .filter(col(\"is_valid_trip\") == True)  # Only process valid trips\n",
        "        .withColumn(\"distance_category\",\n",
        "                   when(col(\"trip_distance\") <= 2, \"short\")\n",
        "                   .when(col(\"trip_distance\") <= 10, \"medium\") \n",
        "                   .otherwise(\"long\"))\n",
        "        .withColumn(\"fare_per_mile\", \n",
        "                   when(col(\"trip_distance\") > 0, \n",
        "                        col(\"fare_amount\") / col(\"trip_distance\"))\n",
        "                   .otherwise(0))\n",
        "        .withColumn(\"pickup_hour\", expr(\"hour(tpep_pickup_datetime)\"))\n",
        "        .withColumn(\"pickup_day_of_week\", expr(\"dayofweek(tpep_pickup_datetime)\"))\n",
        "        .withColumn(\"is_weekend\", \n",
        "                   when(col(\"pickup_day_of_week\").isin([1, 7]), True).otherwise(False))\n",
        "        .withColumn(\"time_period\",\n",
        "                   when(col(\"pickup_hour\").between(6, 11), \"morning\")\n",
        "                   .when(col(\"pickup_hour\").between(12, 17), \"afternoon\")\n",
        "                   .when(col(\"pickup_hour\").between(18, 22), \"evening\")\n",
        "                   .otherwise(\"night\"))\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# GOLD LAYER - Fixed version with watermark and approx_count_distinct\n",
        "# =============================================================================\n",
        "\n",
        "@dlt.table(\n",
        "    name=\"gold.taxi_gold_hourly_metrics\",\n",
        "    comment=\"Hourly aggregated taxi trip metrics for analytics and reporting\",\n",
        "    table_properties={\n",
        "        \"quality\": \"gold\",\n",
        "        \"layer\": \"gold\"\n",
        "    }\n",
        ")\n",
        "def taxi_gold_hourly_metrics():\n",
        "    \"\"\"\n",
        "    Gold layer with hourly aggregations for business intelligence.\n",
        "    \n",
        "    Provides key metrics aggregated by hour for dashboard consumption.\n",
        "    Uses watermark for streaming aggregations and approx_count_distinct for performance.\n",
        "    \"\"\"\n",
        "    return (\n",
        "        dlt.read_stream(\"silver.taxi_silver_trips\")\n",
        "        # Add watermark for streaming aggregations - allow up to 10 minutes of late data\n",
        "        .withWatermark(\"tpep_pickup_datetime\", \"10 minutes\")\n",
        "        .groupBy(\n",
        "            col(\"export_hour\"),\n",
        "            date_trunc(\"hour\", col(\"tpep_pickup_datetime\")).alias(\"pickup_hour_window\"),\n",
        "            col(\"time_period\"),\n",
        "            col(\"is_weekend\")\n",
        "        )\n",
        "        .agg(\n",
        "            count(\"*\").alias(\"total_trips\"),\n",
        "            approx_count_distinct(\"batch_id\").alias(\"unique_batches\"),  # Use approx for streaming\n",
        "            avg(\"trip_distance\").alias(\"avg_distance\"),\n",
        "            avg(\"fare_amount\").alias(\"avg_fare\"),\n",
        "            avg(\"trip_duration_minutes\").alias(\"avg_duration_minutes\"),\n",
        "            avg(\"fare_per_mile\").alias(\"avg_fare_per_mile\"),\n",
        "            min(\"tpep_pickup_datetime\").alias(\"window_start\"),\n",
        "            max(\"tpep_pickup_datetime\").alias(\"window_end\"),\n",
        "            \n",
        "            # Distance category breakdown\n",
        "            count(when(col(\"distance_category\") == \"short\", 1)).alias(\"short_trips\"),\n",
        "            count(when(col(\"distance_category\") == \"medium\", 1)).alias(\"medium_trips\"),\n",
        "            count(when(col(\"distance_category\") == \"long\", 1)).alias(\"long_trips\"),\n",
        "            \n",
        "            # Quality metrics\n",
        "            count(when(col(\"is_valid_trip\") == True, 1)).alias(\"valid_trips\")\n",
        "            # current_timestamp().alias(\"aggregation_timestamp\")\n",
        "        )\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# This cell has been replaced - see cell above for the corrected gold layer function\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
